{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import os.path as osp\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用デバイス：\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルは、2-2-3_Dataset_DataLoaderからコピペすれば良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import make_datapath_list, VOCDataset, DataTransform, Anno_xml2list, od_collate_fn\n",
    "\n",
    "# ファイルパスのリストを取得\n",
    "rootpath = \"./data/VOCdevkit/VOC2012/\"\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "\n",
    "# Datasetを作成\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "               'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "               'cow', 'diningtable', 'dog', 'horse',\n",
    "               'motorbike', 'person', 'pottedplant',\n",
    "               'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "color_mean = (104, 117, 123)   #(BGRの平均)\n",
    "input_size = 300\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase=\"train\",\n",
    "                           transform=DataTransform(input_size, color_mean),\n",
    "                           transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\",\n",
    "                           transform=DataTransform(input_size, color_mean),\n",
    "                           transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
    "\n",
    "val_dataloader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス:  cpu\n",
      "ネットワーク設定完了：学習済みの重みをロードしました\n"
     ]
    }
   ],
   "source": [
    "from utils.ssd_model import SSD\n",
    "\n",
    "# SSD300の設定\n",
    "ssd_cfg = {\n",
    "    'num_classes': 21,  # 背景クラスを含めた合計クラス数\n",
    "    'input_size': 300,  # 画像の入力サイズ\n",
    "    'bbox_aspect_num': [4, 6, 6, 6, 4, 4],      # 出力するDBoxのアスペクト比の種類\n",
    "    'feature_maps': [38, 19, 10, 5, 3, 1],      # 各sourceの画像サイズ\n",
    "    'steps': [8, 16, 32, 64, 100, 300],         # DBoxの大きさを決める\n",
    "    'min_sizes': [30, 60, 111, 162, 213, 264],  # DBoxの大きさを決める\n",
    "    'max_sizes': [60, 111, 162, 213, 264, 315], # DBoxの大きさを決める\n",
    "    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2],],\n",
    "}\n",
    "\n",
    "# SSDネットワークモデル\n",
    "net = SSD(phase='train', cfg=ssd_cfg)\n",
    "\n",
    "# SSDの初期の重みを設定\n",
    "# ssdのvgg部分に重みをロードする\n",
    "vgg_weights = torch.load('./weights/vgg16_reducedfc.pth')\n",
    "net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "# ssdのその他のネットワークの重みはHeの初期値で初期化\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "            \n",
    "# Heの初期値を適用\n",
    "net.extras.apply(weights_init)\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "# GPUが使えるかを確認\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('使用デバイス: ', device)\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードしました')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "# 損失関数の設定\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5, neg_pos=3, device=device)\n",
    "\n",
    "# 最適化手法の設定\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    \n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device('duca:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print('使用デバイス：', device)\n",
    "    \n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "    \n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    logs = []\n",
    "    \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs+1):\n",
    "            \n",
    "            # 開始時刻を保存\n",
    "            t_epoch_start = time.time()\n",
    "            t_iter_start = time.time()\n",
    "            \n",
    "            print('------------')\n",
    "            print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "            print('------------')\n",
    "            \n",
    "            # epochごとの訓練と検証のループ\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    net.train()\n",
    "                else:\n",
    "                    if ((epoch+1)%10 == 0):\n",
    "                        net.eval()\n",
    "                        print('-------------')\n",
    "                        print(' (val) ')\n",
    "                    else:\n",
    "                        # 検証は10回に1回岳行う\n",
    "                        continue\n",
    "                # データローダーからminibatchずつ取り出すループ\n",
    "                for images, targets in dataloaders_dict[phase]:\n",
    "                    \n",
    "                    # GPUが使えるならGPUにデータを送る\n",
    "                    images = images.to(device)\n",
    "                    targets = [ann.to(device) for ann in targets]   # リストの各要素のテンソルをGPUへ\n",
    "                    \n",
    "                    # optimizerを初期化\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # 順伝搬(forward)計算\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        # 順伝搬(forward)計算\n",
    "                        outputs = net(images)\n",
    "                        \n",
    "                        # 損失の計算\n",
    "                        loss_l, loss_c = criterion(outputs, targets)\n",
    "                        loss = loss_l + loss_c\n",
    "                        \n",
    "                        # 訓練時はバックプロぱゲーション\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()  # 勾配の計算\n",
    "                            \n",
    "                            # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
    "                            nn.utils.clip_grad_value_(net.parameters(), clip_value=2.0)\n",
    "                            \n",
    "                            optimizer.step()  # パラメータ更新\n",
    "                            \n",
    "                            if iteration%10 == 0:\n",
    "                                t_iter_finish = time.time()\n",
    "                                duration = t_iter_finish - t_iter_start\n",
    "                                print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(iteration, loss.item(), duration))\n",
    "                                t_iter_start = time.time()\n",
    "                            \n",
    "                            epoch_train_loss += loss.item()\n",
    "                            iteration += 1\n",
    "                        \n",
    "                        # 検証時\n",
    "                        else:\n",
    "                            epoch_val_loss += loss.item()\n",
    "            # epochのphaseごとのlossと正解率\n",
    "            t_epoch_finish = time.time()\n",
    "            print('-------------')\n",
    "            print('epoch {} || Epoch_TRAIN_Loss:{:.4f} || Epoch_VAL_Loss:{:.4f}'.format(epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "            print('timer: {:.4f} sec.'.format(t_epoch_finish-t_epoch_start))\n",
    "            t_epoch_start = time.time()\n",
    "            \n",
    "            # ログを保存\n",
    "            log_epoch = {'epoch': epoch+1, 'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "            logs.append(log_epoch)\n",
    "            df = pd.DataFrame(logs)\n",
    "            df.to_csv('log_output.csv')\n",
    "            \n",
    "            epoch_train_loss = 0.0\n",
    "            epoch_val_loss = 0.0\n",
    "            \n",
    "            # ネットワークを保存する\n",
    "            if (epoch+1)%10==0:\n",
    "                torch.save(net.state_dict(), 'weights/ssd300_' + str(epoch+1) + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cpu\n",
      "------------\n",
      "Epoch 1/2\n",
      "------------\n",
      "イテレーション 10 || Loss: 16.7868 || 10iter: 1236.3402 sec.\n",
      "イテレーション 20 || Loss: 12.0620 || 10iter: 1294.9243 sec.\n",
      "イテレーション 30 || Loss: 11.2808 || 10iter: 1181.5768 sec.\n",
      "イテレーション 40 || Loss: 10.4993 || 10iter: 1060.5368 sec.\n",
      "イテレーション 50 || Loss: 9.1630 || 10iter: 1045.0743 sec.\n",
      "イテレーション 60 || Loss: 8.4397 || 10iter: 1201.9270 sec.\n",
      "イテレーション 70 || Loss: 8.6284 || 10iter: 1175.5674 sec.\n",
      "イテレーション 80 || Loss: 8.3559 || 10iter: 1130.3071 sec.\n",
      "イテレーション 90 || Loss: 8.2356 || 10iter: 1159.9245 sec.\n",
      "イテレーション 100 || Loss: 7.7133 || 10iter: 1082.0769 sec.\n",
      "イテレーション 110 || Loss: 7.8405 || 10iter: 1060.3961 sec.\n",
      "イテレーション 120 || Loss: 7.8749 || 10iter: 1067.8293 sec.\n",
      "イテレーション 130 || Loss: 7.7835 || 10iter: 1063.5420 sec.\n",
      "イテレーション 140 || Loss: 7.7073 || 10iter: 1074.7977 sec.\n",
      "イテレーション 150 || Loss: 8.0081 || 10iter: 1080.5340 sec.\n",
      "イテレーション 160 || Loss: 7.2913 || 10iter: 1078.1935 sec.\n",
      "イテレーション 170 || Loss: 7.0958 || 10iter: 1060.9519 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:1653.8132 || Epoch_VAL_Loss:0.0000\n",
      "timer: 20001.6950 sec.\n",
      "------------\n",
      "Epoch 2/2\n",
      "------------\n",
      "イテレーション 180 || Loss: 7.4113 || 10iter: 130.1049 sec.\n",
      "イテレーション 190 || Loss: 6.8789 || 10iter: 1295.5719 sec.\n",
      "イテレーション 200 || Loss: 7.5257 || 10iter: 1369.3282 sec.\n",
      "イテレーション 210 || Loss: 7.2974 || 10iter: 1275.8000 sec.\n",
      "イテレーション 220 || Loss: 6.6302 || 10iter: 1231.6629 sec.\n",
      "イテレーション 230 || Loss: 6.9483 || 10iter: 1187.3207 sec.\n",
      "イテレーション 240 || Loss: 7.5266 || 10iter: 1082.9287 sec.\n",
      "イテレーション 250 || Loss: 7.0748 || 10iter: 1030.2555 sec.\n",
      "イテレーション 260 || Loss: 6.6636 || 10iter: 1018.7097 sec.\n",
      "イテレーション 270 || Loss: 7.0392 || 10iter: 1022.4651 sec.\n",
      "イテレーション 280 || Loss: 7.1488 || 10iter: 1018.3165 sec.\n",
      "イテレーション 290 || Loss: 6.9618 || 10iter: 1030.8103 sec.\n",
      "イテレーション 300 || Loss: 6.7846 || 10iter: 1024.1000 sec.\n",
      "イテレーション 310 || Loss: 6.8785 || 10iter: 1024.3206 sec.\n",
      "イテレーション 320 || Loss: 6.5548 || 10iter: 1022.4236 sec.\n",
      "イテレーション 330 || Loss: 6.5320 || 10iter: 1059.9526 sec.\n",
      "イテレーション 340 || Loss: 6.5217 || 10iter: 1056.2758 sec.\n",
      "イテレーション 350 || Loss: 6.5173 || 10iter: 1064.8603 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:1259.7131 || Epoch_VAL_Loss:0.0000\n",
      "timer: 19766.6922 sec.\n",
      "------------\n",
      "Epoch 3/2\n",
      "------------\n",
      "イテレーション 360 || Loss: 6.6582 || 10iter: 210.6316 sec.\n",
      "イテレーション 370 || Loss: 6.6113 || 10iter: 1017.6065 sec.\n",
      "イテレーション 380 || Loss: 7.3770 || 10iter: 1020.6044 sec.\n",
      "イテレーション 390 || Loss: 6.3570 || 10iter: 1023.5429 sec.\n",
      "イテレーション 400 || Loss: 6.6978 || 10iter: 1018.4674 sec.\n",
      "イテレーション 410 || Loss: 6.3099 || 10iter: 1018.3864 sec.\n",
      "イテレーション 420 || Loss: 6.2221 || 10iter: 1024.7936 sec.\n",
      "イテレーション 430 || Loss: 6.6385 || 10iter: 1017.4938 sec.\n",
      "イテレーション 440 || Loss: 6.5110 || 10iter: 1015.7882 sec.\n",
      "イテレーション 450 || Loss: 6.6311 || 10iter: 1022.2373 sec.\n",
      "イテレーション 460 || Loss: 6.2190 || 10iter: 1016.0855 sec.\n",
      "イテレーション 470 || Loss: 6.4188 || 10iter: 1015.8673 sec.\n",
      "イテレーション 480 || Loss: 6.7860 || 10iter: 1023.1756 sec.\n",
      "イテレーション 490 || Loss: 6.1207 || 10iter: 1016.3303 sec.\n",
      "イテレーション 500 || Loss: 6.1511 || 10iter: 1018.3406 sec.\n",
      "イテレーション 510 || Loss: 6.2145 || 10iter: 1015.8959 sec.\n",
      "イテレーション 520 || Loss: 6.4393 || 10iter: 1017.0911 sec.\n",
      "イテレーション 530 || Loss: 6.4066 || 10iter: 1028.7058 sec.\n",
      "-------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:1169.2864 || Epoch_VAL_Loss:0.0000\n",
      "timer: 18236.3313 sec.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
